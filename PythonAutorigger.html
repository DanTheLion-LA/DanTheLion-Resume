<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Blog Post — Daniël van Leeuwen</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="stylesheet.css">

</head>

<body>
  <div class="container">
    <h1>Python Autorigger - Web-based auto rigging system</h1>
    <p class="hint"></p>

    <div class="grid">
      <section class="cell">
        <h2>Project Overview</h2>
        <p>The TPose Autorigger was built as part of my graduation project. The goal was to make it easier to prepare characters for use in remote mocap sessions. The tool takes in a character mesh, places the required joints automatically, and produces a rig that can be used inside the TPose platform. By running this through a web server and connecting it to MayaPy, the process becomes accessible without needing a full local setup.</p>
      </section>

      <section class="cell">
        <p>
          <div style=" position:relative; padding-bottom:56.25%; height:0; overflow:hidden; border-radius:12px;">
            <iframe src="https://www.youtube.com/embed/zupK9LBxZwk"
              style="position:absolute; top:0; left:0; width:100%; height:100%; border:0;" allowfullscreen>
            </iframe>
          </div>
        </p>
      </section> 

    <section class="cell">
      <img src="Images/PythonAutoRigger/BrandingPage.png" 
      alt="Explanation of Python AutoRigger"
      style="max-width:100%; height:auto; border-radius:12px;">
    </section>

    <section class="cell">
      <h2>Client & Context</h2>
      <p>The project was developed together with Het Nieuwe Kader, a creative studio in Arnhem. They recently started a new branch called TPose, which focuses on remote motion capture and character animation. The aim of TPose is to make motion capture available without the need for complex studio setups. For that pipeline, a tool was needed that could handle the rigging of characters automatically so that the captured animations could be applied more directly.</p>
    </section>

    <section class="cell">
      <h2>Goals & Challenges</h2>
      <p>The main goal of the project was to create an autorigger that could prepare a character for use in TPose's mocap workflow. This meant reducing the manual work normally involved in placing joints and skinning a mesh. The challenge was to make this process reliable for different kinds of characters while keeping the workflow simple for the end user. Another difficulty was making sure the system could run as part of a web-based platform while still producing rigs of good quality.
      </p>
    </section>

    <section class="cell">
      <img src="Images/PythonAutoRigger/ExplanationImage6.png" 
      alt="Explanation of Python AutoRigger"
      style="max-width:100%; height:auto; border-radius:12px;">
    </section>

    <section class="cell">
      <img src="Images/PythonAutoRigger/ExplanationImage5.png" 
      alt="Explanation of Python AutoRigger"
      style="max-width:100%; height:auto; border-radius:12px;">
    </section>

    <section class="cell">
      <h2>Solution Overview</h2>
      <p>The diagram shows the full pipeline of the Autorigger. The client starts by uploading an FBX character to a Flask server, which is hosted with Waitress. After upload, the character can be inspected and adjusted on a Three.js page, where user input is collected. Both the FBX and the input data are then sent to MayaPy, where the Autorigger runs. The resulting rigged character is exported and returned to the TPose platform, making it available for further use in remote mocap workflows.</p>
    </section>

    <section class="cell">
      <h2>Technical Details</h2>
      <p>On the technical side, I set up a Flask server (served through Waitress) to handle file uploads and route data between the front-end and the backend. A Three.js page was connected to the server so users could preview the character and give input. That input, together with the uploaded FBX, was passed on as JSON and processed in MayaPy, where I wrote Python scripts to generate the rig automatically. Working on this pipeline taught me how to structure a small web service, handle data exchange between different formats, and script in Maya’s Python environment to automate tasks that would normally be done by hand. The source code for this project is available on my GitHub:
        <a href="https://github.com/DanTheLion-LA/Maya-Python-Autorigger" target="_blank" rel="noopener">
          Github Link
        </a>
      </p>
    </section>

    <section class="cell">
      <img src="Images/PythonAutoRigger/ExplanationImage1.png" 
      alt="Explanation of Python AutoRigger"
      style="max-width:100%; height:auto; border-radius:12px;">
    </section>

    <section class="cell">
      <h2>Reflection</h2>
      <p>Through this project I learned a lot about combining different parts of a pipeline into one working system. I had to think about both the technical side of rigging and the usability for people who would be using the platform. It showed me the importance of testing with real users and of keeping the workflow as simple as possible while still producing good results. For future versions, there is room to expand the system to support more character types and to refine the quality of the generated rigs.</p>
    </section>

<!--     <section class="cell">
      <p>Links, call to action, or references.</p>
    </section> -->
  </div>
  </div>
</body>

</html>